{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 511: Data Acquisition and Pre-Processing - Term Project:\n",
    "#### Curated by John Obuch, Fatih Catpinar, and Daniel Larson for Professor Jake Williams - PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Background:\n",
    "__John Obuch:__ Industry experience working with proprietary financial data sets as a Senior BI Analyst for Vanguard. My day-to-day consists of data vissualization, forecasting, and statistical analysis/reporting. The softwares and languages I use include Tableau, RStudio, Python, SQL and Excel. My background is in applied mathematics and economics. I am interested in in scraping/connecting to data using API's. I would also like to gain experience in Natural Language Processing (NLP) and how to clean textual data and prepare it for analysis. Furthermore, I have an interest in learning how to apply machine learning techniques such as Monte Carlo methods, stochastic processes, cosine similarity, and neural networks to analyze the data collected.\n",
    "\n",
    "__Fatih Catpinar:__ PhD candidate in Mechanical Engineering. My research focus is on developing robust and reliable automated control systems for aerial vehicles to improve their stability, performance, and have ability to accommodate loss-of-control failures caused by system/component malfunctions or external hazards. I am interested in learning how to collect data in order to model/simulate a nonlinear system accurately.\n",
    "\n",
    "__Daniel Larson:__ Currently work as a data analyst/data engineering at an R1 institution of higher education. My day-to-day consists of managing a large-scale data warehouse, identifying and creating new data elements that impact student success, and analyzing the impact of initiatives to better resource university services. I work mostly using a combination of SQL, R, Python, and Tableau. I have a Master’s degree in sociology with a  concentration in studying the way wealth impacts an individual’s perceptions and interactions with society. My current interests can be described as understanding how social networks form and impact individuals lives.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Implementation Goals:\n",
    "- Create a social listening data set that ties sentiment across platforms to market indices and currency exchange rates. \n",
    "- Potential end user capabilites include analyzing potential relationships between social networks, and how the data impact markets.\n",
    "- Access the data through API's, web scraping, and data exports.\n",
    "- Clean, join, and structure the data into a data dictionary or data frame for end users to access and utilize for analysis.\n",
    "- Provide interactive user input capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "   In this study, we will be building a data set that will allow end users to explore potential corellations between news/social media platforms and market fluxuations. The data we will use to conduct this study will be obtained from [News API](https://newsapi.org), [Twitter](https://developer.twitter.com/), and [Alpha Vantage](https://www.alphavantage.co/) in addition to other resources as we see fit such as [Exchange Rate Data](https://www.exchangerate-api.com/). We believe the build of this data set will be possible by accessing the data through APIs, web scraping, and downloading data exports. To be able to explore any correlations between market behavior and social media/news platforms, the data we wrangle will need to be queried for a defined time period. We will then perform an inner join of the data on a date field. Potential challenges include, but are not limited to: excluding weekends and holidays, joining the data appropriately, removing stop words, punctuation, and orginizing the textual data into positive and negative sentiment groupings. The data we are collecting was created through people generating textual communication through the use of media platforms, as well as archived pecuniary information through publically accessable financial platforms. Our goal for collecting and curating these data is to allow the end user the ability input their desired search parameters which will output a resulting dataframe for them to analyze the potential impacts of social sentiment with respect to market fluxuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## README!\n",
    "> -\tDue to Twitter term restrictions, we are only able to access tweets with a historical cutoff of 7 days. We were able to grow our dataset by calling 7 days’ worth of data across multiple search terms.\n",
    "> -\tYou are also required to register a Twitter developer account to get your credentials and put them as specified in cred.txt. (https://apps.twitter.com/)\n",
    "> -\tTo access the News API data, you will need to register for an API Key by navigating to (https://newsapi.org)\n",
    "> -\tDue to the Exchange Rate API only displaying same-day rates, we chose to exclude these data from our data set due the API currently limiting the aquisition of historical exchange rate data.\n",
    "> -\tTo access the Exchange Rate API, you will need to acquire an API Key at (https://www.exchangerate-api.com/)\n",
    "> -\tAfter executing the cells below, the `/data` folder will contain Ticker.csv news.csv, twitter.csv, and merged_data.csv files containing seperate files of the data we are collecting.\n",
    "> End user will be able to interact with the notebook by inputing their specified stock ticker, news topics, and twitter key words. The input for the news topics and twitter search terms can either be a single entry, or multiple entires seperated by commas.\n",
    "\n",
    "> __News Data:__ <br>\n",
    "> ##### Powered by News API: NewsAPI.org <br>\n",
    "> Function: `news_topic(topic)`, topic input is a string <br>\n",
    ">Description: Creating pandas data frame based on user input to join on other data. <br>\n",
    ">Size: N rows by 6 columns with page size = 100 with a 100 rows for each topic! To increase sample size, add more topics. (E.g. topic input of 6 entries would produce a dataframe with 600 rows and 6 columns. <br>\n",
    "Format: Each line is a JSON dict which consists of news articles: `author, content, description, publishedAt, source` (__Note:__ the `source` keys value is a dictionary `{id, name}`), and `url.` <br>\n",
    ">Example:<br>\n",
    "> ```\n",
    "{'articles': [{'author': 'Alex Cranz', 'content': 'Youve likely heard about the intense conversations ' 'between the United States and China over tariffs. ' 'The US government has been inconsistent, thus far, ' 'on what affects a trade war could have on the ' 'average person, and the stock marketwhich loves ' 'consistencyha… [+1942 chars]', 'description': 'You’ve likely heard about the intense ' 'conversations between the United States and ' 'China over tariffs. The US government has been ' 'inconsistent, thus far, on what affects a trade ' 'war could have on the average person, and the ' 'stock market—which loves consistency…', 'publishedAt': '2019-05-13T20:50:00Z', 'source': {'id': None, 'name': 'Gizmodo.com'}, 'title': \"A Looming Chinese Trade War Means Either Apple's \" 'Stock Will Drop or iPhone Prices Will Rise', 'url': 'https://gizmodo.com/a-looming-chinese-trade-war-means-either-apples-stock-w-1834729716', 'urlToImage': 'https://i.kinja-img.com/gawker-media/image/upload/s--hL9R82iR--/c_fill,fl_progressive,g_center,h_900,q_80,w_1600/lvsoqy3vgip3k9mn0xxl.jpg'} ,{…}]}\n",
    ">```\n",
    "\n",
    "\n",
    "> __Stock Data:__ <br>\n",
    "> ##### Alpha Vantage <br>\n",
    "> File: Ticker.csv depending on user input. <br>\n",
    "Description: Converts output from API into a pandas dataframe. <br>\n",
    "Size: 100 rows × 10 columns <br>\n",
    "Format: csv files contain headers: `Date, Open, High, Low, Close, AdjClose, Volume, dividend_amount, split_coefficient, and Stock` <br>\n",
    "Example: <br>\n",
    ">```\n",
    "b'timestamp,open,high,low,close,adjusted_close,volume,dividend_amount,split_coefficient\\r\\n2019-06-07,186.5100,191.9200,185.7700,190.1500,190.1500,30684393,0.0000,1.0000\\r\\n2019-06-06,183.0800,185.4700,182.1489,185.2200,185.2200,22526311,0.0000,1.0000\\r\\n2019-06-05,184.2800,184.9900,181.1400,182.5400,182.5400,29773427,0.0000,1.0000\\r\\n\n",
    ">```\n",
    "> __Twitter Data:__ <br>\n",
    "> ##### Twitter API client from importing the Twython module <br>\n",
    ">File: train.tweet.json <br>\n",
    ">Description: outputs dataframe for the keys: `Topic`, `Date`, `User`, `Text` (Topic was a created field). <br>\n",
    ">Size: N rows × 14 columns. The number of rows is dependent on the number of key words the user enters. We receive 100 tweets per date per topic. __Note:__ The number of twitter responses is determined by the number of tweets avalible for a given topic (i.e. even though our limit is 100, we may receive less depending on the topic chosen). <br>\n",
    ">Format: JSON `dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])` <br>\n",
    ">Example: <br>\n",
    ">```\n",
    "[{'contributors': None,\n",
    "  'coordinates': None,\n",
    "  'created_at': 'Sat Jun 08 23:57:54 +0000 2019',\n",
    "  'entities': {'hashtags': [{'indices': [50, 58], 'text': 'maxpain'},\n",
    "                            {'indices': [59, 67], 'text': 'options'}],\n",
    "               'media': [{'display_url': 'pic.twitter.com/QWBqSBoB7H',\n",
    "                          'expanded_url': 'https://twitter.com/optioncharts/status/1137509083345559552/photo/1',\n",
    "                          'id': 1137509082435338240,\n",
    "                          'id_str': '1137509082435338240',\n",
    "                          'indices': [92, 115],\n",
    "                          'media_url': 'http://pbs.twimg.com/media/D8k-e9NWwAASuzw.jpg',\n",
    "                          'media_url_https': 'https://pbs.twimg.com/media/D8k-e9NWwAASuzw.jpg',\n",
    "                          'sizes': {'large': {'h': 500,\n",
    "                                              'resize': 'fit',\n",
    "                                              'w': 1200},\n",
    "                                    'medium': {'h': 500,\n",
    "                                               'resize': 'fit',\n",
    "                                               'w': 1200},\n",
    "                                    'small': {'h': 283,\n",
    "                                              'resize': 'fit',\n",
    "                                              'w': 680},\n",
    "                                    'thumb': {'h': 150,\n",
    "                                              'resize': 'crop',\n",
    "                                              'w': 150}},\n",
    "                          'type': 'photo',\n",
    "                          'url': 'https://t.co/QWBqSBoB7H'}],\n",
    "               'symbols': [{'indices': [0, 5], 'text': 'AAPL'}],\n",
    "               'urls': [{'display_url': 'maximum-pain.com/options/max-pa…',\n",
    "                         'expanded_url': 'http://maximum-pain.com/options/max-pain/AAPL',\n",
    "                         'indices': [68, 91],\n",
    "                         'url': 'https://t.co/CCUsRwhEoM'}],\n",
    "               'user_mentions': []},\n",
    "  'extended_entities': {'media': [{'display_url': 'pic.twitter.com/QWBqSBoB7H',\n",
    "                                   'expanded_url': 'https://twitter.com/optioncharts/status/1137509083345559552/photo/1',\n",
    "                                   'id': 1137509082435338240,\n",
    "                                   'id_str': '1137509082435338240',\n",
    "                                   'indices': [92, 115],\n",
    "                                   'media_url': 'http://pbs.twimg.com/media/D8k-e9NWwAASuzw.jpg',\n",
    "                                   'media_url_https': 'https://pbs.twimg.com/media/D8k-e9NWwAASuzw.jpg',\n",
    "                                   'sizes': {'large': {'h': 500,\n",
    "                                                       'resize': 'fit',\n",
    "                                                       'w': 1200},\n",
    "                                             'medium': {'h': 500,\n",
    "                                                        'resize': 'fit',\n",
    "                                                        'w': 1200},\n",
    "                                             'small': {'h': 283,\n",
    "                                                       'resize': 'fit',\n",
    "                                                       'w': 680},\n",
    "                                             'thumb': {'h': 150,\n",
    "                                                       'resize': 'crop',\n",
    "                                                       'w': 150}},\n",
    "                                   'type': 'photo',\n",
    "                                   'url': 'https://t.co/QWBqSBoB7H'}]},\n",
    "  'favorite_count': 2,\n",
    "  'favorited': False,\n",
    "  'geo': None,\n",
    "  'id': 1137509083345559552,\n",
    "  'id_str': '1137509083345559552',\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'is_quote_status': False,\n",
    "  'lang': 'en',\n",
    "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
    "  'place': None,\n",
    "  'possibly_sensitive': False,\n",
    "  'retweet_count': 0,\n",
    "  'retweeted': False,\n",
    "  'source': '<a href=\"http://maximum-pain.com\" rel=\"nofollow\">maxpain</a>',\n",
    "  'text': '$AAPL Max Pain is 180.00 for maturity 06/14/2019. #maxpain #options '\n",
    "          'https://t.co/CCUsRwhEoM https://t.co/QWBqSBoB7H',\n",
    "  'truncated': False,\n",
    "  'user': {'contributors_enabled': False,\n",
    "           'created_at': 'Sun Apr 03 21:22:18 +0000 2016',\n",
    "           'default_profile': True,\n",
    "           'default_profile_image': False,\n",
    "           'description': '',\n",
    "           'entities': {'description': {'urls': []},\n",
    "                        'url': {'urls': [{'display_url': 'maximum-pain.com',\n",
    "                                          'expanded_url': 'http://maximum-pain.com',\n",
    "                                          'indices': [0, 23],\n",
    "                                          'url': 'https://t.co/eIsTCt8fCQ'}]}},\n",
    "           'favourites_count': 15,\n",
    "           'follow_request_sent': None,\n",
    "           'followers_count': 1449,\n",
    "           'following': None,\n",
    "           'friends_count': 10,\n",
    "           'geo_enabled': False,\n",
    "           'has_extended_profile': False,\n",
    "           'id': 716737614771044352,\n",
    "           'id_str': '716737614771044352',\n",
    "           'is_translation_enabled': False,\n",
    "           'is_translator': False,\n",
    "           'lang': 'en',\n",
    "           'listed_count': 53,\n",
    "           'location': '',\n",
    "           'name': 'max pain',\n",
    "           'notifications': None,\n",
    "           'profile_background_color': 'F5F8FA',\n",
    "           'profile_background_image_url': None,\n",
    "           'profile_background_image_url_https': None,\n",
    "           'profile_background_tile': False,\n",
    "           'profile_banner_url': 'https://pbs.twimg.com/profile_banners/716737614771044352/1468284199',\n",
    "           'profile_image_url': 'http://pbs.twimg.com/profile_images/752664674416619520/cdAjb6AU_normal.jpg',\n",
    "           'profile_image_url_https': 'https://pbs.twimg.com/profile_images/752664674416619520/cdAjb6AU_normal.jpg',\n",
    "           'profile_link_color': '1DA1F2',\n",
    "           'profile_sidebar_border_color': 'C0DEED',\n",
    "           'profile_sidebar_fill_color': 'DDEEF6',\n",
    "           'profile_text_color': '333333',\n",
    "           'profile_use_background_image': True,\n",
    "           'protected': False,\n",
    "           'screen_name': 'optioncharts',\n",
    "           'statuses_count': 161829,\n",
    "           'time_zone': None,\n",
    "           'translator_type': 'none',\n",
    "           'url': 'https://t.co/eIsTCt8fCQ',\n",
    "           'utc_offset': None,\n",
    "           'verified': False}}]\n",
    ">```\n",
    "\n",
    "\n",
    ">\n",
    "> __Exchange Rate Data:__ <br>\n",
    "> ##### Powered by Exchange Rate API <br>\n",
    ">File: JSON Object <br>\n",
    ">Description: Putting Data into pandas dataframe <br>\n",
    ">Size: 52 rows by 5 columns, where the pandas index is the exchange currency short name <br>\n",
    ">Format: JSON Dictionary <br>\n",
    ">Example: <br>\n",
    ">```\n",
    ">{'base': 'USD', 'date': '2019-06-07', 'rates': {'AED': 3.672459, 'ARS': 44.899611, 'AUD': 1.43252, 'BGN': 1.737344, 'BRL': 3.876962, 'BSD': 1, 'CAD': 1.339201, 'CHF': 0.991815,…}, 'time_last_updated': 1559866243}\n",
    ">```\n",
    "\n",
    "> __Files Produced After Executing the Script:__ <br>\n",
    "ticker.csv <br>\n",
    "news.csv <br>\n",
    "twitter.csv <br>\n",
    "merged_data.csv <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Vantage for Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import dateutil.parser as dateparser\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "# https://www.alphavantage.co/support/#api-key\n",
    "# Welcome to Alpha Vantage! Your dedicated access key is: F9Q151K1ZRYQXU2D. \n",
    "\n",
    "# default downloads last 100 data. There is an option to download 20 years\n",
    "\n",
    "def download_market_data(user_input_ticker):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    \n",
    "    user_input = input('Enter Ticker: ')\n",
    "\n",
    "    # to be safe upper the user input and strip it\n",
    "    ticker = user_input.upper().strip()\n",
    "    key = \"F9Q151K1ZRYQXU2D\"\n",
    "    URL = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=\"+str(ticker)+\"&apikey=\"+str(key)+\"&datatype=csv\"\n",
    "    r = requests.get(URL)\n",
    "    #print(r.content)\n",
    "    Name = str(ticker) + '.csv'\n",
    "    Dir = 'data/'+ Name\n",
    "    open(Dir,'wb').write(r.content)\n",
    "    \n",
    "    data = pd.read_csv(Dir)\n",
    "    # type(data[\"timestamp\"][0]) # the time type is str so we need to change it to datetime\n",
    "    def convert_data(data):\n",
    "        '''Building datetime and converting to datetime object'''\n",
    "        return dateparser.parse(data['timestamp'])\n",
    "    \n",
    "    data['timestamp'] = data.apply(convert_data, axis = 1) #Converting date object to datetime\n",
    "    data = data.rename(columns={'timestamp': 'Date'})\n",
    "    \n",
    "    # Add stock name\n",
    "    #data['Stock'] = [str(ticker)] * len(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_stock = download_market_data('')\n",
    "# data_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Powered by News API: NewsAPI.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Access US Techknology News\n",
    "from pprint import pprint #Importing Modules\n",
    "import csv, json, requests, xmltodict, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import dateutil.parser as dateparser\n",
    "\n",
    "def news_topic(user_input):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    \n",
    "    user_input = input('Enter Your Key Word(s) Here Seperate By A Comma: ')\n",
    "    user_keys = user_input.split(',')\n",
    "    NEWS = pd.DataFrame(columns = ['Date','key_word','web_source','author','title','content'])\n",
    "    \n",
    "    for i in range(len(user_keys)):\n",
    "        news_key = 'e184e11177244726a5fb2aae3f24737f' #Calling data (Please do not share API key) #To specify date range from=2019-05-20&to=2019-05-22&\n",
    "        news_response = requests.get('https://newsapi.org/v2/everything?q='+str(user_keys[i].strip())+'&language=en&pageSize=100&apiKey='+news_key) #change q= to the topic of interest\n",
    "        data = news_response.json()\n",
    "        #pprint(data)\n",
    "        articles = data['articles'] #List of Articles each article is a dictionary\n",
    "        list_of_lists = []\n",
    "        header = ['Date','key_word','web_source','author','title','content']\n",
    "        for book in articles:\n",
    "            content = book['content'] #Obtaining the data by accessing it through the dictionary keys of interest\n",
    "            title = book['title']\n",
    "            author = book['author']\n",
    "            key_word = str(user_keys[i].strip())\n",
    "            Date = dateparser.parse(book['publishedAt'].split('T')[0]) #Note that Date here is pub_time\n",
    "            web_source = book['source']['name']\n",
    "            temp_list = [Date,key_word,web_source,author,title,content]\n",
    "            list_of_lists.append(temp_list)\n",
    "        df_news_topic = pd.DataFrame(list_of_lists, columns=header) \n",
    "        NEWS = pd.concat([NEWS, df_news_topic])\n",
    "        New_News = NEWS.sort_values(by=['Date']).reset_index(drop = True)\n",
    "        \n",
    "        New_News.to_csv('data/news.csv')\n",
    "        \n",
    "    return New_News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_news = news_topic('')\n",
    "# data_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #API access keys (Do not distribute Dan's keys) rate exceeded for now... try back later\n",
    "# access_token = \"32600877-SUEQzAuJDuZPEdAvorNzX3usuLAENHTPmGVk0eXuF\"\n",
    "# access_token_secret = \"PA16VhIdjerpVprzcRD6bZl4YlXervAUlQSPeztvAyA70\"\n",
    "# consumer_key = \"wOj58vqE8onMQYAFBeAnUgHcC\"\n",
    "# consumer_secret = \"8Hh8l7FWeZoXjHV4emQ4EwQ9yBFMZjIYhlAt15O5vP4rNfawMa\"\n",
    "\n",
    "#API access keys (Do not distribute John's keys)\n",
    "access_token = \"1119415411697754113-Qc69oiuO0nXwvTWQaWBwJmrkNoIdNj\"\n",
    "access_token_secret = \"krGY6Qgpw03ZwDJ83JPooN0dI0KpWB1QOdKVqDQ4yc3V1\"\n",
    "consumer_key = \"jwYY1yljXGaoaOliNxYYJDAO8\"\n",
    "consumer_secret = \"egS8nBoXombQyWczHlRDZSeUbGhISyQbZF3WbVTWp4g9fuxCeY\"\n",
    "\n",
    "#Importing modules\n",
    "import time\n",
    "import dateutil.parser as dateparser\n",
    "from datetime import datetime\n",
    "from twython import Twython\n",
    "import pandas as pd\n",
    "\n",
    "def get_Twitter_data(user_input):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    \n",
    "    user_input = input('Enter Topic(s) seperate with commas: ')\n",
    "    user_keys = user_input.split(',')\n",
    "\n",
    "    twitter = Twython(consumer_key, consumer_secret)\n",
    "    #tweets = {}\n",
    "    list_of_lists_tweets = []\n",
    "    header = ['Topic','Date','User','Text']\n",
    "    #Try to perform same user interactiveness as in the news using the input() function\n",
    "    #search_terms = ['Stockmarket','markets','invest','daytrade','investors','apple', 'Trump'] ## Need to add to this list\n",
    "    search_terms = user_keys\n",
    "    # date_list =['2019-05-07','2019-05-08']\n",
    "\n",
    "    last_days = 10 #Twitter only allows us to pull the last 10 days worth of data. So we would need to run periodically to build out a larger dataset\n",
    "    d = int(str(datetime.now().date()).split('-')[2])\n",
    "\n",
    "    \n",
    "    #Testing to try and automate twitter date range\n",
    "    #print((str(datetime.now().date())[0:8]))\n",
    "    \n",
    "    for i in range(d-last_days+2,d+2):\n",
    "    #for date in date_list:\n",
    "        date = str(datetime.now().date())[0:8]+str(i)\n",
    "\n",
    "        for term in search_terms:\n",
    "            #print(term)                                                #count max = 100, adjust as needed.\n",
    "            for tweet in twitter.search(q = term.strip(), until = date, count = 100)[\"statuses\"]:## Need to think of some terms to search. One approach here might be to identify someone who is a ##leading indstry person, pullling all their tweets, idendifying what tags they use and than loopin ## through\n",
    "                #Converting 'created_at' to match datetime objects for stock data and news data so we can perform a merge.\n",
    "                tweet['created_at'] = time.strftime('%Y-%m-%d %H:%M:%S %p', \\\n",
    "                                                        time.strptime(tweet['created_at'], \\\n",
    "                                                        '%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "                Date = dateparser.parse(tweet['created_at'].split()[0])\n",
    "                User = tweet['user']['screen_name']\n",
    "                Text = tweet['text']\n",
    "                Topic = term\n",
    "                temp_L = [Topic,Date,User,Text]\n",
    "                list_of_lists_tweets.append(temp_L)\n",
    "                df_tweets = pd.DataFrame(list_of_lists_tweets, columns=header)\n",
    "    \n",
    "    df_tweets.to_csv('data/twitter.csv')\n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_twitter = get_Twitter_data('')\n",
    "# data_twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Join Of Stock Data With News Data (Stock Data + NEWS = MERGE_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try to join the two dataframes with a left join such that the stock data is our primary data source where we are joining on Date using pythons `pd.merge()` fucntion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######\n",
    "#Notes\n",
    "######\n",
    "#To merge on multiple columns, do on=[a,b,c]\n",
    "\n",
    "#merged_data1 = pd.merge(data_stock, data_news, how='left', on='Date')\n",
    "#merged_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfoming Second Join (MERGE_1 + TWITTER = MERGE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_data2 = pd.merge(merged_data1,data_twitter, how='left', on='Date')\n",
    "#merged_data2 #This merged the data, but we are seeing duplicative entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows with NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Look! ######\n",
    "#This is our final dataframe after ridding the data of na's\n",
    "\n",
    "#merged_data = merged_data2.dropna().reset_index(drop = True)\n",
    "#merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidating Functions \n",
    "(Run the following two cells to see final dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil.parser as dateparser\n",
    "from datetime import datetime\n",
    "from pprint import pprint #Importing Modules\n",
    "import csv, json, requests, xmltodict, re, time\n",
    "import numpy as np\n",
    "from twython import Twython\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "def download_market_data(user_input_ticker_for_stock):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    \n",
    "    user_input = user_input_ticker_for_stock\n",
    "    ticker = user_input.upper().strip()\n",
    "    key = \"F9Q151K1ZRYQXU2D\"\n",
    "    URL = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=\"+str(ticker)+\"&apikey=\"+str(key)+\"&datatype=csv\"\n",
    "    try:\n",
    "        r = requests.get(URL)\n",
    "\n",
    "        Dir = 'data/'+ str(ticker) + '.csv'\n",
    "        open(Dir,'wb').write(r.content)\n",
    "\n",
    "        data = pd.read_csv(Dir)\n",
    "        # type(data[\"timestamp\"][0]) # the time type is str so we need to change it to datetime\n",
    "        def convert_data(data):\n",
    "            '''Building datetime and converting to datetime object'''\n",
    "            return dateparser.parse(data['timestamp'])\n",
    "\n",
    "        data['timestamp'] = data.apply(convert_data, axis = 1) #Converting date object to datetime\n",
    "        data = data.rename(columns={'timestamp': 'Date'})\n",
    "\n",
    "        # Add stock name\n",
    "        data['Stock'] = [str(ticker)] * len(data)\n",
    "        stock_data = data\n",
    "\n",
    "        return stock_data\n",
    "    except:\n",
    "        print('Not a valid ticker')\n",
    "        \n",
    "####################################################################################################################\n",
    "\n",
    "\n",
    "def news_topic(user_input_for_news):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    try:\n",
    "        user_input = user_input_for_news\n",
    "        user_keys = user_input.split(',')\n",
    "        NEWS = pd.DataFrame(columns = ['Date','News_key_word','News_web_source','News_author','News_title','News_content'])\n",
    "\n",
    "        for i in range(len(user_keys)):\n",
    "            news_key = 'e184e11177244726a5fb2aae3f24737f' #Calling data (Please do not share API key) #To specify date range from=2019-05-20&to=2019-05-22&\n",
    "            news_response = requests.get('https://newsapi.org/v2/everything?q='+str(user_keys[i].strip())+'&language=en&pageSize=100&apiKey='+news_key) #change q= to the topic of interest\n",
    "            data = news_response.json()\n",
    "            #pprint(data)\n",
    "            articles = data['articles'] #List of Articles each article is a dictionary\n",
    "            list_of_lists = []\n",
    "            header = ['Date','News_key_word','News_web_source','News_author','News_title','News_content']\n",
    "            for book in articles:\n",
    "                content = book['content'] #Obtaining the data by accessing it through the dictionary keys of interest\n",
    "                title = book['title']\n",
    "                author = book['author']\n",
    "                key_word = str(user_keys[i].strip())\n",
    "                Date = dateparser.parse(book['publishedAt'].split('T')[0]) #Note that Date here is pub_time\n",
    "                web_source = book['source']['name']\n",
    "                temp_list = [Date,key_word,web_source,author,title,content]\n",
    "                list_of_lists.append(temp_list)\n",
    "            df_news_topic = pd.DataFrame(list_of_lists, columns=header) \n",
    "            NEWS = pd.concat([NEWS, df_news_topic])\n",
    "            New_News = NEWS.sort_values(by=['Date']).reset_index(drop = True)\n",
    "\n",
    "            New_News.to_csv('data/news.csv')\n",
    "\n",
    "        return New_News\n",
    "    except:\n",
    "        print('Not a news keyword')\n",
    "        \n",
    "####################################################################################################################\n",
    "\n",
    "#API access keys (Do not distribute)\n",
    "access_token = \"1119415411697754113-Qc69oiuO0nXwvTWQaWBwJmrkNoIdNj\"\n",
    "access_token_secret = \"krGY6Qgpw03ZwDJ83JPooN0dI0KpWB1QOdKVqDQ4yc3V1\"\n",
    "consumer_key = \"jwYY1yljXGaoaOliNxYYJDAO8\"\n",
    "consumer_secret = \"egS8nBoXombQyWczHlRDZSeUbGhISyQbZF3WbVTWp4g9fuxCeY\"\n",
    "\n",
    "def get_Twitter_data(user_input_for_twitter):\n",
    "    \n",
    "    '''This function returns a dataframe based on the topic(s) the user inputs'''\n",
    "    try:\n",
    "        user_input = user_input_for_twitter\n",
    "        user_keys = user_input.split(',')\n",
    "\n",
    "        twitter = Twython(consumer_key, consumer_secret)\n",
    "        #tweets = {}\n",
    "        list_of_lists_tweets = []\n",
    "        header = ['Twitter_Topic','Date','Twitter_User','Twitter_Text']\n",
    "        search_terms = user_keys\n",
    "        last_days = 10 #Twitter only allows us to pull the last 10 days worth of data. So we would need to run periodically to build out a larger dataset\n",
    "        d = int(str(datetime.now().date()).split('-')[2])\n",
    "\n",
    "        for i in range(d-last_days+2,d+2):\n",
    "            date = str(datetime.now().date())[0:8]+str(i)\n",
    "\n",
    "            for term in search_terms:\n",
    "                #print(term)                                                #count max = 100, adjust as needed.\n",
    "                for tweet in twitter.search(q = term.strip(), until = date, count = 100)[\"statuses\"]:## Need to think of some terms to search. One approach here might be to identify someone who is a ##leading indstry person, pullling all their tweets, idendifying what tags they use and than loopin ## through\n",
    "                    #Converting 'created_at' to match datetime objects for stock data and news data so we can perform a merge.\n",
    "                    tweet['created_at'] = time.strftime('%Y-%m-%d %H:%M:%S %p', \\\n",
    "                                                            time.strptime(tweet['created_at'], \\\n",
    "                                                            '%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "                    Date = dateparser.parse(tweet['created_at'].split()[0])\n",
    "                    User = tweet['user']['screen_name']\n",
    "                    Text = tweet['text']\n",
    "                    Topic = term\n",
    "                    temp_L = [Topic,Date,User,Text]\n",
    "                    list_of_lists_tweets.append(temp_L)\n",
    "                    df_tweets = pd.DataFrame(list_of_lists_tweets, columns=header)\n",
    "\n",
    "        df_tweets.to_csv('data/twitter.csv')\n",
    "        return df_tweets\n",
    "    except:\n",
    "        print('Not a twitter tag')\n",
    "        \n",
    "####################################################################################################################\n",
    "\n",
    "def merge_all(data1_stock,data2_news,data3_twitter):\n",
    "    try:\n",
    "        merged_data1 = pd.merge(data1_stock, data2_news, how='left', on='Date')\n",
    "        merged_data2 = pd.merge(merged_data1,data3_twitter, how='left', on='Date')\n",
    "        merged_data = merged_data2.dropna().reset_index(drop = True)\n",
    "\n",
    "        merged_data.to_csv('data/merged_data.csv')\n",
    "\n",
    "        return merged_data\n",
    "    except:\n",
    "        print('Invalid input for merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell and input your desired search terms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Ticker For stock: AAPL\n",
      "Enter Your Key Word(s) Here Seperate By A Comma for news: Tim Cook, news, dog, cat\n",
      "Enter Topic(s) seperate with commas for Twitter: animal, cake\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>Stock</th>\n",
       "      <th>News_key_word</th>\n",
       "      <th>News_web_source</th>\n",
       "      <th>News_author</th>\n",
       "      <th>News_title</th>\n",
       "      <th>News_content</th>\n",
       "      <th>Twitter_Topic</th>\n",
       "      <th>Twitter_User</th>\n",
       "      <th>Twitter_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>ceciliapaivaa</td>\n",
       "      <td>RT @gabrechaves: Pessoal, precisa de adotantes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>DavidRoseQ13FOX</td>\n",
       "      <td>Lacey Police would like to reunite this pig wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>WHlNING</td>\n",
       "      <td>(animal crossing animal crossing animal crossi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>jamesabernard</td>\n",
       "      <td>RT @DefendingBeef: This is similar to the type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>idontknowyet528</td>\n",
       "      <td>RT @jawsum_art: 🕯\\n              🕯         🕯\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>AmysGotBirds</td>\n",
       "      <td>@sjillmcdaniel @walterowensgrpa @CNN Also, ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>gIossuIt</td>\n",
       "      <td>RT @TXTPeru: ⭐️ Due to the #100DaysWithTXT, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>needsfixingnow</td>\n",
       "      <td>RT @heidiallen75: These sentences do not come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>TraciHusse</td>\n",
       "      <td>RT @KeithOlbermann: LIZ IS MARKED FOR DEATH TO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>oliveoil7291</td>\n",
       "      <td>RT @MattBellassai: fun fact Beyoncé actually a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>_Jud_B</td>\n",
       "      <td>Los antropólogos aún no terminamos de comprend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>emilyrlitvack</td>\n",
       "      <td>RT @PimaAnimalCare: Now you can shop for PACC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>LeXanderMan</td>\n",
       "      <td>RT @BrainsEscape: I have a question. With ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>marqueviis</td>\n",
       "      <td>6 años que laburo como un animal y no progreso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>jewellsmom</td>\n",
       "      <td>Wild Animal Cafes Are Anything but Cute #care2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>WickedTimo</td>\n",
       "      <td>RT @bocasfave: me and my mutuals waiting for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>Depredador9006</td>\n",
       "      <td>RT @IA_Mexico: .@PastelesMarisa puede cambiar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>PennieDPortgas</td>\n",
       "      <td>RT @ngamethecube: If Animal Crossing gets a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>itzeldelrey</td>\n",
       "      <td>@Sarah_Loftis1 @dxnielit ma’am... it still inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>aliuhhh</td>\n",
       "      <td>RT @sendafriendco: Send a cute stuffed animal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>Floorsquartinii</td>\n",
       "      <td>RT @Emipivetta_: No al maltrato animal!!!! Dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>CatsCauseTypos</td>\n",
       "      <td>RT @CryptoNature: Which harmful animal behavio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>boxspringm</td>\n",
       "      <td>RT @coywolfassoc: Theresa Laden &amp;amp; Marion R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>GiuliCGonzales</td>\n",
       "      <td>RT @femilimon: DIFUNDID POR FAVOR.\\nCaso de ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>asia_erwin</td>\n",
       "      <td>RT @imskytrash: nobody:\\n\\nanimal crossing vil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>maikesalves</td>\n",
       "      <td>RT @idiotdoodoohead: ANIMAL CROSSING SLASHERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>OKBlu_</td>\n",
       "      <td>So shocking that an animal would act like an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>LUCY16866698</td>\n",
       "      <td>RT @ipandacom: You trying to ask dad for some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>jacky_yay</td>\n",
       "      <td>RT @GameXplain: When André discovered Animal C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>191.81</td>\n",
       "      <td>195.37</td>\n",
       "      <td>191.62</td>\n",
       "      <td>192.58</td>\n",
       "      <td>192.58</td>\n",
       "      <td>26198036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Matt Novak</td>\n",
       "      <td>Facebook Suspends Natural News, Founder Calls ...</td>\n",
       "      <td>Facebook has suspended Natural News from posti...</td>\n",
       "      <td>animal</td>\n",
       "      <td>litten2000</td>\n",
       "      <td>RT @SplatoonNews: NEWS: To celebrate the #Fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14751</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>enzox25x</td>\n",
       "      <td>RT @ItsFoodPorn: Chocolate layered Cake. https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14752</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>Bodie_Sattva</td>\n",
       "      <td>RT @DopplerJess: I think it's safe to say this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14753</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>BrendanKLieb</td>\n",
       "      <td>@randi_real @sweetiehour @rosehartsweets @lynf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14754</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>bam1a_cake</td>\n",
       "      <td>RT @25Dectmxb: น่ารัก~~ https://t.co/RW8SVLFG0o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14755</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>Source_Nintendo</td>\n",
       "      <td>@cake_hoarder This isn't everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14756</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>Jerry_Puente</td>\n",
       "      <td>@huffines28 @cake_hoarder @danaxboop https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14757</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>annaolwig</td>\n",
       "      <td>RT @basegahwd: Jersey: Blues\\nSocks: Cardinals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14758</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>katatonictonic</td>\n",
       "      <td>RT @justcastellon: HELP SPREAD THE WORD\\n\\nLet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14759</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>_RL_W</td>\n",
       "      <td>@Peezkyweezky @NialElkim @uppittynegress @vand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14760</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>Lory_cake</td>\n",
       "      <td>@Kamipa_ Eu vou levar isso como um sinal q tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14761</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>cake_hoarder</td>\n",
       "      <td>@dril @comradedugan i say we keep the rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14762</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>907FrostieBalls</td>\n",
       "      <td>@keywrath @NudeEskimo It’s special because of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14763</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>utahpowerhouse</td>\n",
       "      <td>We can have our cake and eat it too! What a fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14764</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>malik_hassan21</td>\n",
       "      <td>RT @CoryBeesler: Bella made me a cake for my b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14765</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>yoshi_wowtokyo</td>\n",
       "      <td>Who made you this cake?\\n\\nは忘れてください😭\\n\\nWho yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14766</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>tothehospital</td>\n",
       "      <td>I made cake for no reason lol https://t.co/gp2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14767</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>mlp_Noteshifter</td>\n",
       "      <td>*He gets a slice of chocolate cake and heads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14768</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>abcdefghiluvyou</td>\n",
       "      <td>Tomorrow (today) is my ex bestie‘s birthday. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14769</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>huffines28</td>\n",
       "      <td>@Jerry_Puente @cake_hoarder @danaxboop Sup it’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14770</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>mayrabella101</td>\n",
       "      <td>RT @NYDailyNews: Walmart gave a Texas family a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>piece_of_cake_s</td>\n",
       "      <td>家出て通学中にお腹もう空いたは早すぎる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14772</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>AmorKourtney</td>\n",
       "      <td>@_livingbeauty Girl! Gotta dig for the cake 🙄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14773</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>5primeto3prime</td>\n",
       "      <td>Guys it’s my birthday tomorrow...I’m hoping th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14774</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>aestheticjdn</td>\n",
       "      <td>RT @justcastellon: HELP SPREAD THE WORD\\n\\nLet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14775</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>D2DNotary</td>\n",
       "      <td>Queen of cake! #beautyintheworld https://t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14776</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>lftrev</td>\n",
       "      <td>RT @GhouliaChilds: Meringue BLOODY BONES Red V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14777</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>chrisyanke</td>\n",
       "      <td>Walmart sells family Styrofoam graduation cake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14778</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>VaVeros</td>\n",
       "      <td>@HerHandsMyHands Pssst! I got cake too! All ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14779</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>odetojinnie</td>\n",
       "      <td>@btsfanmomma @AOmelas @BTS_twt i made this cak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14780</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>175.60</td>\n",
       "      <td>177.92</td>\n",
       "      <td>170.27</td>\n",
       "      <td>173.30</td>\n",
       "      <td>173.30</td>\n",
       "      <td>40396069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>Cnet.com</td>\n",
       "      <td>Lynn La</td>\n",
       "      <td>Apple updates watchOS 6, adds voice memo and c...</td>\n",
       "      <td>Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...</td>\n",
       "      <td>cake</td>\n",
       "      <td>SilamSiva</td>\n",
       "      <td>Can we skip to Sunday already so I can have my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14781 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    open    high     low   close  adjusted_close    volume  \\\n",
       "0     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "1     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "2     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "3     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "4     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "5     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "6     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "7     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "8     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "9     2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "10    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "11    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "12    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "13    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "14    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "15    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "16    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "17    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "18    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "19    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "20    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "21    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "22    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "23    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "24    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "25    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "26    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "27    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "28    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "29    2019-06-10  191.81  195.37  191.62  192.58          192.58  26198036   \n",
       "...          ...     ...     ...     ...     ...             ...       ...   \n",
       "14751 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14752 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14753 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14754 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14755 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14756 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14757 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14758 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14759 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14760 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14761 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14762 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14763 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14764 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14765 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14766 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14767 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14768 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14769 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14770 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14771 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14772 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14773 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14774 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14775 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14776 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14777 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14778 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14779 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "14780 2019-06-03  175.60  177.92  170.27  173.30          173.30  40396069   \n",
       "\n",
       "       dividend_amount  split_coefficient Stock News_key_word News_web_source  \\\n",
       "0                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "1                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "2                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "3                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "4                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "5                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "6                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "7                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "8                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "9                  0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "10                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "11                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "12                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "13                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "14                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "15                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "16                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "17                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "18                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "19                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "20                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "21                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "22                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "23                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "24                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "25                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "26                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "27                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "28                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "29                 0.0                1.0  AAPL          news     Gizmodo.com   \n",
       "...                ...                ...   ...           ...             ...   \n",
       "14751              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14752              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14753              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14754              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14755              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14756              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14757              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14758              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14759              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14760              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14761              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14762              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14763              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14764              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14765              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14766              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14767              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14768              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14769              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14770              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14771              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14772              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14773              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14774              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14775              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14776              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14777              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14778              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14779              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "14780              0.0                1.0  AAPL      Tim Cook        Cnet.com   \n",
       "\n",
       "      News_author                                         News_title  \\\n",
       "0      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "1      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "2      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "3      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "4      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "5      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "6      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "7      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "8      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "9      Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "10     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "11     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "12     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "13     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "14     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "15     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "16     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "17     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "18     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "19     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "20     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "21     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "22     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "23     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "24     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "25     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "26     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "27     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "28     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "29     Matt Novak  Facebook Suspends Natural News, Founder Calls ...   \n",
       "...           ...                                                ...   \n",
       "14751     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14752     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14753     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14754     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14755     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14756     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14757     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14758     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14759     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14760     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14761     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14762     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14763     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14764     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14765     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14766     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14767     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14768     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14769     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14770     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14771     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14772     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14773     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14774     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14775     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14776     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14777     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14778     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14779     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "14780     Lynn La  Apple updates watchOS 6, adds voice memo and c...   \n",
       "\n",
       "                                            News_content Twitter_Topic  \\\n",
       "0      Facebook has suspended Natural News from posti...        animal   \n",
       "1      Facebook has suspended Natural News from posti...        animal   \n",
       "2      Facebook has suspended Natural News from posti...        animal   \n",
       "3      Facebook has suspended Natural News from posti...        animal   \n",
       "4      Facebook has suspended Natural News from posti...        animal   \n",
       "5      Facebook has suspended Natural News from posti...        animal   \n",
       "6      Facebook has suspended Natural News from posti...        animal   \n",
       "7      Facebook has suspended Natural News from posti...        animal   \n",
       "8      Facebook has suspended Natural News from posti...        animal   \n",
       "9      Facebook has suspended Natural News from posti...        animal   \n",
       "10     Facebook has suspended Natural News from posti...        animal   \n",
       "11     Facebook has suspended Natural News from posti...        animal   \n",
       "12     Facebook has suspended Natural News from posti...        animal   \n",
       "13     Facebook has suspended Natural News from posti...        animal   \n",
       "14     Facebook has suspended Natural News from posti...        animal   \n",
       "15     Facebook has suspended Natural News from posti...        animal   \n",
       "16     Facebook has suspended Natural News from posti...        animal   \n",
       "17     Facebook has suspended Natural News from posti...        animal   \n",
       "18     Facebook has suspended Natural News from posti...        animal   \n",
       "19     Facebook has suspended Natural News from posti...        animal   \n",
       "20     Facebook has suspended Natural News from posti...        animal   \n",
       "21     Facebook has suspended Natural News from posti...        animal   \n",
       "22     Facebook has suspended Natural News from posti...        animal   \n",
       "23     Facebook has suspended Natural News from posti...        animal   \n",
       "24     Facebook has suspended Natural News from posti...        animal   \n",
       "25     Facebook has suspended Natural News from posti...        animal   \n",
       "26     Facebook has suspended Natural News from posti...        animal   \n",
       "27     Facebook has suspended Natural News from posti...        animal   \n",
       "28     Facebook has suspended Natural News from posti...        animal   \n",
       "29     Facebook has suspended Natural News from posti...        animal   \n",
       "...                                                  ...           ...   \n",
       "14751  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14752  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14753  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14754  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14755  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14756  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14757  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14758  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14759  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14760  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14761  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14762  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14763  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14764  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14765  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14766  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14767  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14768  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14769  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14770  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14771  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14772  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14773  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14774  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14775  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14776  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14777  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14778  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14779  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "14780  Apple CEO Tim Cook at WWDC 2019.\\r\\nScreenshot...          cake   \n",
       "\n",
       "          Twitter_User                                       Twitter_Text  \n",
       "0        ceciliapaivaa  RT @gabrechaves: Pessoal, precisa de adotantes...  \n",
       "1      DavidRoseQ13FOX  Lacey Police would like to reunite this pig wi...  \n",
       "2              WHlNING  (animal crossing animal crossing animal crossi...  \n",
       "3        jamesabernard  RT @DefendingBeef: This is similar to the type...  \n",
       "4      idontknowyet528  RT @jawsum_art: 🕯\\n              🕯         🕯\\n...  \n",
       "5         AmysGotBirds  @sjillmcdaniel @walterowensgrpa @CNN Also, ani...  \n",
       "6             gIossuIt  RT @TXTPeru: ⭐️ Due to the #100DaysWithTXT, fo...  \n",
       "7       needsfixingnow  RT @heidiallen75: These sentences do not come ...  \n",
       "8           TraciHusse  RT @KeithOlbermann: LIZ IS MARKED FOR DEATH TO...  \n",
       "9         oliveoil7291  RT @MattBellassai: fun fact Beyoncé actually a...  \n",
       "10              _Jud_B  Los antropólogos aún no terminamos de comprend...  \n",
       "11       emilyrlitvack  RT @PimaAnimalCare: Now you can shop for PACC ...  \n",
       "12         LeXanderMan  RT @BrainsEscape: I have a question. With ever...  \n",
       "13          marqueviis  6 años que laburo como un animal y no progreso...  \n",
       "14          jewellsmom  Wild Animal Cafes Are Anything but Cute #care2...  \n",
       "15          WickedTimo  RT @bocasfave: me and my mutuals waiting for a...  \n",
       "16      Depredador9006  RT @IA_Mexico: .@PastelesMarisa puede cambiar ...  \n",
       "17      PennieDPortgas  RT @ngamethecube: If Animal Crossing gets a fi...  \n",
       "18         itzeldelrey  @Sarah_Loftis1 @dxnielit ma’am... it still inf...  \n",
       "19             aliuhhh  RT @sendafriendco: Send a cute stuffed animal ...  \n",
       "20     Floorsquartinii  RT @Emipivetta_: No al maltrato animal!!!! Dif...  \n",
       "21      CatsCauseTypos  RT @CryptoNature: Which harmful animal behavio...  \n",
       "22          boxspringm  RT @coywolfassoc: Theresa Laden &amp; Marion R...  \n",
       "23      GiuliCGonzales  RT @femilimon: DIFUNDID POR FAVOR.\\nCaso de ma...  \n",
       "24          asia_erwin  RT @imskytrash: nobody:\\n\\nanimal crossing vil...  \n",
       "25         maikesalves  RT @idiotdoodoohead: ANIMAL CROSSING SLASHERS ...  \n",
       "26              OKBlu_  So shocking that an animal would act like an a...  \n",
       "27        LUCY16866698  RT @ipandacom: You trying to ask dad for some ...  \n",
       "28           jacky_yay  RT @GameXplain: When André discovered Animal C...  \n",
       "29          litten2000  RT @SplatoonNews: NEWS: To celebrate the #Fina...  \n",
       "...                ...                                                ...  \n",
       "14751         enzox25x  RT @ItsFoodPorn: Chocolate layered Cake. https...  \n",
       "14752     Bodie_Sattva  RT @DopplerJess: I think it's safe to say this...  \n",
       "14753     BrendanKLieb  @randi_real @sweetiehour @rosehartsweets @lynf...  \n",
       "14754       bam1a_cake    RT @25Dectmxb: น่ารัก~~ https://t.co/RW8SVLFG0o  \n",
       "14755  Source_Nintendo                @cake_hoarder This isn't everything  \n",
       "14756     Jerry_Puente  @huffines28 @cake_hoarder @danaxboop https://t...  \n",
       "14757        annaolwig  RT @basegahwd: Jersey: Blues\\nSocks: Cardinals...  \n",
       "14758   katatonictonic  RT @justcastellon: HELP SPREAD THE WORD\\n\\nLet...  \n",
       "14759            _RL_W  @Peezkyweezky @NialElkim @uppittynegress @vand...  \n",
       "14760        Lory_cake  @Kamipa_ Eu vou levar isso como um sinal q tro...  \n",
       "14761     cake_hoarder         @dril @comradedugan i say we keep the rats  \n",
       "14762  907FrostieBalls  @keywrath @NudeEskimo It’s special because of ...  \n",
       "14763   utahpowerhouse  We can have our cake and eat it too! What a fu...  \n",
       "14764   malik_hassan21  RT @CoryBeesler: Bella made me a cake for my b...  \n",
       "14765   yoshi_wowtokyo  Who made you this cake?\\n\\nは忘れてください😭\\n\\nWho yo...  \n",
       "14766    tothehospital  I made cake for no reason lol https://t.co/gp2...  \n",
       "14767  mlp_Noteshifter  *He gets a slice of chocolate cake and heads t...  \n",
       "14768  abcdefghiluvyou  Tomorrow (today) is my ex bestie‘s birthday. I...  \n",
       "14769       huffines28  @Jerry_Puente @cake_hoarder @danaxboop Sup it’...  \n",
       "14770    mayrabella101  RT @NYDailyNews: Walmart gave a Texas family a...  \n",
       "14771  piece_of_cake_s                                家出て通学中にお腹もう空いたは早すぎる  \n",
       "14772     AmorKourtney      @_livingbeauty Girl! Gotta dig for the cake 🙄  \n",
       "14773   5primeto3prime  Guys it’s my birthday tomorrow...I’m hoping th...  \n",
       "14774     aestheticjdn  RT @justcastellon: HELP SPREAD THE WORD\\n\\nLet...  \n",
       "14775        D2DNotary  Queen of cake! #beautyintheworld https://t.co/...  \n",
       "14776           lftrev  RT @GhouliaChilds: Meringue BLOODY BONES Red V...  \n",
       "14777       chrisyanke  Walmart sells family Styrofoam graduation cake...  \n",
       "14778          VaVeros  @HerHandsMyHands Pssst! I got cake too! All ha...  \n",
       "14779      odetojinnie  @btsfanmomma @AOmelas @BTS_twt i made this cak...  \n",
       "14780        SilamSiva  Can we skip to Sunday already so I can have my...  \n",
       "\n",
       "[14781 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input_ticker_for_stock =  input('Enter Ticker For stock: ')\n",
    "user_input_for_news = input('Enter Your Key Word(s) Here Seperate By A Comma for news: ')\n",
    "user_input_for_twitter = input('Enter Topic(s) seperate with commas for Twitter: ')\n",
    "\n",
    "Stock_data = download_market_data(user_input_ticker_for_stock)\n",
    "News_data = news_topic(user_input_for_news)\n",
    "Tweets_data = get_Twitter_data(user_input_for_twitter)\n",
    "Merged_data = merge_all(Stock_data,News_data,Tweets_data)\n",
    "Merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test individual outputs\n",
    "\n",
    "#Stock_data.head()\n",
    "#News_data.head()\n",
    "#Tweets_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Future Continuation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Tokenize Textual Data... (This is work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS WILL THROW AN ERROR ###\n",
    "#Trying to tokenize sentences in the data frame\n",
    "#Testing Something\n",
    "#df['Token_Text'] = df.apply(lambda row: nltk.word_tokenize(row['Text']), axis=1)\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "### IDEAS ###\n",
    "\n",
    "#words = word_tokenize(sentence)\n",
    "\n",
    "# for index, row in merged_data2.iterrows():\n",
    "#     merged_data2['Text'][index].strip().split()\n",
    "#     merged_data2['title'][index].strip().split()\n",
    "#     merged_data2['content'][index].strip().split()\n",
    "    #merged_data2['Token_Text'] = merged_data2.apply(lambda row: nltk.word_tokenize(row['Text']), axis=1)\n",
    "#     Token_Text_List = nltk.word_tokenize(merged_data2['Text'][index].strip())\n",
    "#     Token_title_List = nltk.word_tokenize(merged_data2['title'][index].strip())\n",
    "#     Token_content_List = nltk.word_tokenize(merged_data2['content'][index].strip())\n",
    "# print(Token_Text_List[2])    \n",
    "# merged_data2['title'][index] = merged_data2['title'][index].split()\n",
    "# print(merged_data2['title'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exchange Rate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Powered By Exchange Rate API\n",
    "Current limitation is that this API does not offer historical exchange rate data per the [documentation](https://www.exchangerate-api.com/#faq_anchor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>date</th>\n",
       "      <th>rates</th>\n",
       "      <th>time_last_updated</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AED</th>\n",
       "      <td>USD</td>\n",
       "      <td>2019-06-11 00:00:00</td>\n",
       "      <td>3.672573</td>\n",
       "      <td>1560211804</td>\n",
       "      <td>2019-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARS</th>\n",
       "      <td>USD</td>\n",
       "      <td>2019-06-11 00:00:00</td>\n",
       "      <td>44.836788</td>\n",
       "      <td>1560211804</td>\n",
       "      <td>2019-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUD</th>\n",
       "      <td>USD</td>\n",
       "      <td>2019-06-11 00:00:00</td>\n",
       "      <td>1.433549</td>\n",
       "      <td>1560211804</td>\n",
       "      <td>2019-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGN</th>\n",
       "      <td>USD</td>\n",
       "      <td>2019-06-11 00:00:00</td>\n",
       "      <td>1.730875</td>\n",
       "      <td>1560211804</td>\n",
       "      <td>2019-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRL</th>\n",
       "      <td>USD</td>\n",
       "      <td>2019-06-11 00:00:00</td>\n",
       "      <td>3.878580</td>\n",
       "      <td>1560211804</td>\n",
       "      <td>2019-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    base                 date      rates  time_last_updated       Date\n",
       "AED  USD  2019-06-11 00:00:00   3.672573         1560211804 2019-06-11\n",
       "ARS  USD  2019-06-11 00:00:00  44.836788         1560211804 2019-06-11\n",
       "AUD  USD  2019-06-11 00:00:00   1.433549         1560211804 2019-06-11\n",
       "BGN  USD  2019-06-11 00:00:00   1.730875         1560211804 2019-06-11\n",
       "BRL  USD  2019-06-11 00:00:00   3.878580         1560211804 2019-06-11"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import requests\n",
    "import dateutil.parser as dateparser\n",
    "\n",
    "# Where USD is the base currency you want to use\n",
    "url = 'https://api.exchangerate-api.com/v4/latest/USD'\n",
    "\n",
    "# Making our request\n",
    "response = requests.get(url)    \n",
    "data = response.json()\n",
    "#pprint(data)\n",
    "Exchange_Rates = pd.DataFrame(data)\n",
    "#df['date']['USD'] = dateparser.parse(df['date']['USD'])\n",
    "Exchg_CCY = []\n",
    "list_of_lists_CCY = []\n",
    "#header = ['Date','Rates']\n",
    "#print(index)\n",
    "for index, row in Exchange_Rates.iterrows():\n",
    "    Exchg_CCY.append(index)\n",
    "    Exchange_Rates['date'][index] = dateparser.parse(Exchange_Rates['date'][index].split()[0])\n",
    "    #I don't think we need this date index? I am trying to create column such that we can merge.\n",
    "    if index in Exchg_CCY:\n",
    "        Exchange_Rates['Date'] = Exchange_Rates['date'][index]\n",
    "#print(type())\n",
    "        #Exchange_Rates['Exchange'] == Exchange_Rates[index]    \n",
    "Exchange_Rates.head()\n",
    "#print(Exchange_Rates.keys())\n",
    "\n",
    "\n",
    "######THIS GIVES A WARNING. I'M NOT SURE IF THIS A PROBLEM?############ IT GIVES OUTPUT THOUGH...\n",
    "\n",
    "###Trying to include the index for the associated market exchange\n",
    "\n",
    "# Date = Exchange_Rates['date']\n",
    "# #Exchange = Exchange_Rates[index]\n",
    "# Rates = Exchange_Rates['rates']\n",
    "# temp_L = [Date,Rates]\n",
    "# list_of_lists_CCY.append(temp_L)\n",
    "# df_CCY = pd.DataFrame(list_of_lists_CCY, columns=header)\n",
    "# print(type(Exchange_Rates['date']['BGN']))\n",
    "\n",
    "# df_CCY.head()\n",
    "\n",
    "# print('')\n",
    "# print(type(df['date']['USD']))\n",
    "# # Your JSON object\n",
    "# print (data)\n",
    "# print(type(data['rates']['AUD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting Third Merge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unable to merge data due to the date being tomorrow. and tomorrow is not in the dates of merged_data2 would need to concatinate each day or something\n",
    "\n",
    "#merged_data3 = pd.merge(Exchange_Rates,merged_data2, how='inner', on='Date')\n",
    "#merged_data3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unable to perform a third merge due to date not aligning correctly. Additionally, the indices have been modified..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Stakeholders and Data Distribution:\n",
    "Financial Firms such as Vanguard and BlackRock would be interested in understing if these data contain any potential correlations between market data and social sentiment. Understanding the hypothesized impact social networks have on the market would allow these entities to be able to provide informed investement suggestions to their clients. Additionally, it could provide aid in attempting to beat the market based on a portfolios sensativity to daily news dialouge. Another stakeholder who would be interested in this data would be FinTech. Other interested consumers include, but are not limited to: studends, financial researchers, and investors.\n",
    "\n",
    "When distributing the data to stakeholders and other interested parties, some api keys may need to be provided to the end user running the code in order to access the data. Additionally links to the web pages where the data was aquired will also need to be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Limitations and Improvements:\n",
    "Current improvements to the data include being able to query a more historical sample of articles and exchange rate data. Another improvement that we can make to the dataset would be to add columns computationally with respect to some of the market data we are collecting. This will allow us to obtain further information that was not initially included in the dataset, but can be obtained computationally from the data we have. Looking back at some obsticales we encountered, we expereinced difficulty with scraping Yahoo Finance data to provide a url for the user to click on such that the csv file downloads automatically. We worked around this by discovering an alternative website that provided the same resulting data. The News data could be improved by obtaining various topics accross all the news platforms avalible through the API. An improvement that we can make to the twitter data, would be to associate keys words of key words to stream tweets. To explain further, if we have a key word of Apple which populates a textual output, we would want the key words withing that output to be added to our search query. Additionally, this data could be improved by only pulling tweets from specified users such as Jeff Benzos or Tim Cook. Another limitation from twitter is that we were unable to isolate tweets ensuring that the key word returns the correct data (e.g. Apple the company, VS apple the fruit). We also did not consider re-tweets or tweets created by bots. For our stock market data, the user my not know the ticker symbol of the company they are interested in querrying. We could supply search input cell such that user can input the company name, and they will be navigated to a google url page that provides them with the associated stock ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
